{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26154ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/yyb02274/yolov5\")  # ÎÑ§ yolov5 Î£®Ìä∏ Í≤ΩÎ°ú\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "from models.yolo import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.yolo import Model\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "cfg_path = 'models/yolov5s.yaml'\n",
    "weights_path = 'runs/train/baseline_yolov5s/weights/best.pt'\n",
    "num_classes = 80\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ±\n",
    "with open(cfg_path) as f:\n",
    "    model_cfg = yaml.safe_load(f)\n",
    "\n",
    "model = Model(model_cfg, ch=3, nc=num_classes).to(device)\n",
    "model.eval()\n",
    "\n",
    "checkpoint = torch.load(weights_path, map_location=device, weights_only=False)\n",
    "state_dict = checkpoint['model'].state_dict()\n",
    "model.load_state_dict(state_dict)\n",
    "print(\"‚úÖ Î™®Îç∏ Íµ¨Ï°∞ Î∞è Í∞ÄÏ§ëÏπò Î°úÎî© ÏôÑÎ£å\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a322c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn as nn\n",
    "\n",
    "prune_rate = 0.5\n",
    "modules_to_prune = []\n",
    "\n",
    "print(f\"L1 Unstructured Pruning ÏãúÏûë (ÎπÑÏú®: {prune_rate * 100:.0f}%)\")\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        print(f\" ‚Üí {name} pruning Ï†ÅÏö© Ï§ë...\")\n",
    "        prune.l1_unstructured(module, name='weight', amount=prune_rate)\n",
    "        modules_to_prune.append((module, 'weight'))\n",
    "\n",
    "print(\"Í∞ÄÏßÄÏπòÍ∏∞ ÏûÑÏãú Ï†ÅÏö© ÏôÑÎ£å (reparametrization ÏÉÅÌÉú)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module, param_name in modules_to_prune:\n",
    "    \n",
    "    if hasattr(module, param_name + \"_mask\"):\n",
    "        prune.remove(module, param_name)\n",
    "\n",
    "print(\"‚úÖ pruning Í≤∞Í≥ºÎ•º Î™®Îç∏Ïóê ÏòÅÍµ¨ Î∞òÏòÅÌñàÏäµÎãàÎã§ (weight_mask Ï†úÍ±∞ ÏôÑÎ£å)\")\n",
    "\n",
    "print(\"weight_orig Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏ (ÏÉÅÏúÑ 3Í∞ú):\")\n",
    "for module, _ in modules_to_prune[:3]:\n",
    "    print('weight_orig' in module._parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"runs/train/baseline_yolov5s/weights/pruned_ratio[0.5].pt\"\n",
    "torch.save({'model': model}, ckpt_path)\n",
    "print(f\"üì¶ YOLOv5Ïö© checkpoint Ï†ÄÏû• ÏôÑÎ£å: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afaf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_sparsity(model):\n",
    "    total_zeros = 0\n",
    "    total_elements = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.requires_grad:\n",
    "            total_zeros += torch.sum(param == 0).item()\n",
    "            total_elements += param.numel()\n",
    "    sparsity = 100.0 * total_zeros / total_elements\n",
    "    return sparsity, total_zeros, total_elements\n",
    "\n",
    "sparsity, total_zeros, total_elements = calculate_global_sparsity(model)\n",
    "print(f\"üìâ Ï†ÑÏ≤¥ sparsity: {sparsity:.2f}%\")\n",
    "print(f\"   ‚Üí 0Ïù∏ weight Ïàò: {total_zeros:,} / Ï†ÑÏ≤¥ weight Ïàò: {total_elements:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_nonzeros(model):\n",
    "    nonzero = total = 0\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'mask' in name:\n",
    "            continue  # pruning maskÎäî Î∂ÑÏÑù ÎåÄÏÉÅÏóêÏÑú Ï†úÏô∏\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        nz_count = np.count_nonzero(tensor)\n",
    "        total_params = np.prod(tensor.shape)\n",
    "        nonzero += nz_count\n",
    "        total += total_params\n",
    "        print(f'{name:40} | nonzeros = {nz_count:9} / {total_params:9} '\n",
    "              f'({100 * nz_count / total_params:6.2f}%) | '\n",
    "              f'total_pruned = {total_params - nz_count:9} | shape = {tensor.shape}')\n",
    "    \n",
    "    pruned = total - nonzero\n",
    "    compression = total / nonzero if nonzero > 0 else float('inf')\n",
    "    pruned_percent = 100 * pruned / total\n",
    "    print(\"-\" * 100)\n",
    "    print(f'TOTAL ‚Üí alive: {nonzero:,}, pruned: {pruned:,}, total: {total:,}')\n",
    "    print(f'       Compression rate: {compression:10.2f}x   ({pruned_percent:6.2f}% pruned)')\n",
    "\n",
    "print_nonzeros(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyp_custom.yaml\", \"w\") as f:\n",
    "    f.write(\"\"\"lr0: 0.001\n",
    "lrf: 0.01\n",
    "momentum: 0.937\n",
    "weight_decay: 0.0005\n",
    "warmup_epochs: 3.0\n",
    "warmup_momentum: 0.8\n",
    "warmup_bias_lr: 0.1\n",
    "box: 0.05\n",
    "cls: 0.5\n",
    "cls_pw: 1.0\n",
    "obj: 1.0\n",
    "obj_pw: 1.0\n",
    "iou_t: 0.20\n",
    "anchor_t: 4.0\n",
    "fl_gamma: 0.0\n",
    "hsv_h: 0.015\n",
    "hsv_s: 0.7\n",
    "hsv_v: 0.4\n",
    "degrees: 0.0\n",
    "translate: 0.1\n",
    "scale: 0.5\n",
    "shear: 0.0\n",
    "perspective: 0.0\n",
    "flipud: 0.0\n",
    "fliplr: 0.5\n",
    "mosaic: 1.0\n",
    "mixup: 0.0\n",
    "copy_paste: 0.0\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "  --weights runs/train/baseline_yolov5s/weights/pruned_ratio[0.5].pt\\\n",
    "  --data data/coco128.yaml \\\n",
    "  --cfg models/yolov5s.yaml \\\n",
    "  --hyp hyp_custom.yaml \\\n",
    "  --epochs 20 \\\n",
    "  --batch-size 16 \\\n",
    "  --name retrain_pruned \\\n",
    "  --exist-ok\n",
    "  #ÍπåÏßÄÎäî Ï†ïÏÉÅÏûëÎèô!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_mask_to_weight(model):\n",
    "    num_applied = 0\n",
    "    for m in model.modules():\n",
    "        if hasattr(m, \"weight\") and hasattr(m, \"mask\"):\n",
    "            with torch.no_grad():\n",
    "                m.weight.data.mul_(m.mask)\n",
    "            num_applied += 1\n",
    "    print(f\"[freeze_mask_to_weight] applied to {num_applied} layers.\")\n",
    "\n",
    "# pruned_ckpt Î∂àÎü¨Ïò§Í∏∞\n",
    "import torch\n",
    "ckpt = torch.load(\"runs/train/baseline_yolov5s/weights/pruned_ratio[0.5].pt\", map_location=\"cpu\", weights_only=False)\n",
    "model = ckpt['model'] if 'model' in ckpt else ckpt  # YOLOv5 Íµ¨Ï°∞Ïùº Í≤ΩÏö∞ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n",
    "\n",
    "freeze_mask_to_weight(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, json, torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Ï†ÄÏû• ÏúÑÏπò\n",
    "SAVE_DIR = Path(\"csr_dump_ratio[0.5]\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 0Ïù¥ ÏïÑÎãå Í∞íÏúºÎ°ú Í∞ÑÏ£ºÌï† ÏûÑÍ≥ÑÍ∞í (ÏôÑÏ†ÑÌûà 0Ïù¥Î©¥ 0.0, ÌòπÏùÄ 1e-12)\n",
    "THRESH = 0.0\n",
    "\n",
    "def to_csr_2d(mat: np.ndarray, thresh=0.0):\n",
    "    \"\"\"2D numpy array -> CSR(row_ptr, col_ind, values)\"\"\"\n",
    "    rows, cols = mat.shape\n",
    "    row_ptr = [0]\n",
    "    col_ind, values = [], []\n",
    "    nnz = 0\n",
    "    for r in range(rows):\n",
    "        nz_cols = np.nonzero(np.abs(mat[r]) > thresh)[0]\n",
    "        col_ind.extend(nz_cols.tolist())\n",
    "        values.extend(mat[r, nz_cols].tolist())\n",
    "        nnz += len(nz_cols)\n",
    "        row_ptr.append(nnz)\n",
    "    return np.array(row_ptr, np.int64), np.array(col_ind, np.int32), np.array(values, np.float32)\n",
    "\n",
    "def export_model_to_csr(model, save_dir, thresh=0.0):\n",
    "    \"\"\"Conv/Linear Î†àÏù¥Ïñ¥Î•º CSRÎ°ú Ï†ÄÏû•ÌïòÍ≥† manifest.json ÏÉùÏÑ±\"\"\"\n",
    "    manifest = {\"layers\": []}\n",
    "\n",
    "    for name, m in model.named_modules():\n",
    "        if not (hasattr(m, \"weight\") and isinstance(getattr(m, \"weight\", None), torch.Tensor)):\n",
    "            continue\n",
    "\n",
    "        W = m.weight.detach().cpu().numpy()\n",
    "\n",
    "        # Conv\n",
    "        if W.ndim == 4:\n",
    "            O, I, kH, kW = W.shape\n",
    "            W2 = W.reshape(O, I * kH * kW)\n",
    "            shape2d, orig_shape, kind = (O, I*kH*kW), (O, I, kH, kW), \"conv2d\"\n",
    "        # Linear\n",
    "        elif W.ndim == 2:\n",
    "            W2 = W\n",
    "            shape2d, orig_shape, kind = W.shape, W.shape, \"linear\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # CSR Î≥ÄÌôò\n",
    "        rp, ci, val = to_csr_2d(W2, thresh)\n",
    "\n",
    "        # ÏïàÏ†ÑÌïú ÌååÏùº Ïù¥Î¶Ñ\n",
    "        safe_name = name.replace(\".\", \"_\")\n",
    "        np.savez(save_dir / f\"{safe_name}.npz\",\n",
    "                 row_ptr=rp, col_ind=ci, values=val)\n",
    "\n",
    "        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í∏∞Î°ù\n",
    "        manifest[\"layers\"].append({\n",
    "            \"name\": name,\n",
    "            \"type\": kind,\n",
    "            \"shape\": list(orig_shape),\n",
    "            \"shape2d\": list(shape2d),\n",
    "            \"nnz\": int(val.size),\n",
    "            \"density\": float(val.size) / float(np.prod(shape2d))\n",
    "        })\n",
    "\n",
    "    # manifest Ï†ÄÏû•\n",
    "    with open(save_dir / \"manifest_ratio[0.5].json\", \"w\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Saved CSR dump to: {save_dir.resolve()} | layers: {len(manifest['layers'])}\")\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "export_model_to_csr(model, SAVE_DIR, thresh=THRESH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Round-trip Í≤ÄÏ¶ù: CSR -> dense Î≥µÏõê == ÏõêÎ≥∏ weight ? ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SAVE_DIR = Path(\"csr_dump_ratio[0.5]\")     # CSR Îç§ÌîÑ ÏúÑÏπò\n",
    "THRESH = 0.0                    # ÎÇ¥Î≥¥ÎÇº Îïå ÏçºÎçò ÏûÑÍ≥ÑÍ∞íÍ≥º ÎèôÏùºÌïòÍ≤å\n",
    "MAX_PRINT = 10                  # ÎØ∏Ïä§Îß§Ïπò ÏµúÎåÄ ÌëúÏãú Í∞úÏàò\n",
    "\n",
    "def csr_to_dense(row_ptr, col_ind, values, shape2d):\n",
    "    rows, cols = shape2d\n",
    "    dense = np.zeros((rows, cols), dtype=np.float32)\n",
    "    for r in range(rows):\n",
    "        s, e = int(row_ptr[r]), int(row_ptr[r+1])\n",
    "        cols_r = col_ind[s:e]\n",
    "        vals_r = values[s:e]\n",
    "        dense[r, cols_r] = vals_r\n",
    "    return dense\n",
    "\n",
    "# manifest Î∂àÎü¨Ïò§Í∏∞\n",
    "mani_path = SAVE_DIR / \"manifest_ratio[0.5].json\"\n",
    "assert mani_path.exists(), f\"manifest_ratio[0.5].json not found in {SAVE_DIR}\"\n",
    "manifest = json.load(open(mani_path, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# modelÏùò Î™®Îìà dict (Ïù¥Î¶Ñ‚ÜíÎ™®Îìà)\n",
    "module_map = dict(model.named_modules())\n",
    "\n",
    "checked, mismatches = 0, []\n",
    "\n",
    "for meta in manifest[\"layers\"]:\n",
    "    name   = meta[\"name\"]\n",
    "    shape2 = tuple(meta[\"shape2d\"])\n",
    "    kind   = meta[\"type\"]\n",
    "\n",
    "    # CSR ÌååÏùº Î°úÎìú (export Ïãú '.' -> '_'Î°ú Ï†ÄÏû•ÌñàÏùå)\n",
    "    npz_path = SAVE_DIR / f\"{name.replace('.', '_')}.npz\"\n",
    "    z = np.load(npz_path)\n",
    "    dense = csr_to_dense(z[\"row_ptr\"], z[\"col_ind\"], z[\"values\"], shape2)\n",
    "\n",
    "    # ÏõêÎ≥∏ Í∞ÄÏ§ëÏπò Í∫ºÎÇ¥ÏÑú 2DÎ°ú Ìé¥Í∏∞\n",
    "    mod = module_map.get(name, None)\n",
    "    if mod is None or not hasattr(mod, \"weight\"):\n",
    "        mismatches.append((name, \"module-not-found\"))\n",
    "        continue\n",
    "\n",
    "    W = mod.weight.detach().cpu().numpy()\n",
    "    if kind == \"conv2d\":\n",
    "        O, I, kH, kW = meta[\"shape\"]\n",
    "        W2 = W.reshape(O, I * kH * kW)\n",
    "    else:\n",
    "        W2 = W  # linear\n",
    "\n",
    "    # ÎπÑÍµê: (1) nnz ÎèôÏùº? (2) Í∞í ÏôÑÏ†Ñ ÎèôÏùº?\n",
    "    nnz_W2 = int(np.count_nonzero(np.abs(W2) > THRESH))\n",
    "    nnz_csr = int(z[\"values\"].size)\n",
    "\n",
    "    same_nnz = (nnz_W2 == nnz_csr)\n",
    "    same_vals = np.allclose(W2, dense, atol=0.0, rtol=0.0)\n",
    "\n",
    "    if not (same_nnz and same_vals):\n",
    "        reason = []\n",
    "        if not same_nnz: reason.append(f\"nnz {nnz_W2} != {nnz_csr}\")\n",
    "        if not same_vals: reason.append(\"values differ\")\n",
    "        mismatches.append((name, \", \".join(reason)))\n",
    "    checked += 1\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"Checked layers: {checked}\")\n",
    "if mismatches:\n",
    "    print(f\"‚ùå Mismatches: {len(mismatches)} (showing up to {MAX_PRINT})\")\n",
    "    for n, r in mismatches[:MAX_PRINT]:\n",
    "        print(f\" - {n}: {r}\")\n",
    "else:\n",
    "    print(\"‚úÖ All matched perfectly (CSR round-trip OK)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
